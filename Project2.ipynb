{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637e1ec0",
   "metadata": {},
   "source": [
    "## Another approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8b3f3a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/mirayon/anaconda3/lib/python3.11/site-packages (4.41.2)\n",
      "Requirement already satisfied: filelock in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from transformers) (0.23.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: torch in /Users/mirayon/anaconda3/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.2.1)\n",
      "Requirement already satisfied: pandas in /Users/mirayon/anaconda3/lib/python3.11/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mirayon/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eab829b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23b6839e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flags</th>\n",
       "      <th>instruction</th>\n",
       "      <th>category</th>\n",
       "      <th>intent</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>question about cancelling order {{Order Number}}</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I've understood you have a question regarding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BQZ</td>\n",
       "      <td>i have a question about cancelling oorder {{Or...</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I've been informed that you have a question ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLQZ</td>\n",
       "      <td>i need help cancelling puchase {{Order Number}}</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I can sense that you're seeking assistance wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BL</td>\n",
       "      <td>I need to cancel purchase {{Order Number}}</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I understood that you need assistance with can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCELN</td>\n",
       "      <td>I cannot afford this order, cancel purchase {{...</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I'm sensitive to the fact that you're facing f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   flags                                        instruction category  \\\n",
       "0      B   question about cancelling order {{Order Number}}    ORDER   \n",
       "1    BQZ  i have a question about cancelling oorder {{Or...    ORDER   \n",
       "2   BLQZ    i need help cancelling puchase {{Order Number}}    ORDER   \n",
       "3     BL         I need to cancel purchase {{Order Number}}    ORDER   \n",
       "4  BCELN  I cannot afford this order, cancel purchase {{...    ORDER   \n",
       "\n",
       "         intent                                           response  \n",
       "0  cancel_order  I've understood you have a question regarding ...  \n",
       "1  cancel_order  I've been informed that you have a question ab...  \n",
       "2  cancel_order  I can sense that you're seeking assistance wit...  \n",
       "3  cancel_order  I understood that you need assistance with can...  \n",
       "4  cancel_order  I'm sensitive to the fact that you're facing f...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Dataset\n",
    "file_path = 'Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Inspect the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2177115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Text Data\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Lowercase text\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Remove text in square brackets\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove punctuation\n",
    "    return text.strip()\n",
    "\n",
    "# Apply cleaning to 'instruction' and 'response' columns\n",
    "data['instruction'] = data['instruction'].apply(clean_text)\n",
    "data['response'] = data['response'].apply(clean_text)\n",
    "\n",
    "# Handle missing values\n",
    "data.dropna(subset=['instruction', 'response'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f06a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data for Fine-Tuning\n",
    "# Concatenate 'instruction' and 'response' for fine-tuning as input-output pairs\n",
    "data['input_output'] = data['instruction'] + ' ' + data['response']\n",
    "\n",
    "# Use a smaller subset of the dataset for quicker training\n",
    "data_subset = data.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# Save the processed data to a text file\n",
    "processed_data_path = 'processed_data.txt'\n",
    "with open(processed_data_path, 'w') as f:\n",
    "    for line in data_subset['input_output']:\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e966e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mirayon/Documents/Softwares/anaconda3/lib/python3.11/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Prepare Data for Fine-Tuning\n",
    "def load_dataset(file_path, tokenizer):\n",
    "    return TextDataset(\n",
    "        tokenizer=tokenizer,\n",
    "        file_path=file_path,\n",
    "        block_size=128)\n",
    "\n",
    "def create_data_collator(tokenizer):\n",
    "    return DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer,\n",
    "        mlm=False)\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "\n",
    "train_dataset = load_dataset(processed_data_path, tokenizer)\n",
    "data_collator = create_data_collator(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb7603bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset and Data Collator\n",
    "def load_dataset(file_path, tokenizer):\n",
    "    return TextDataset(\n",
    "        tokenizer=tokenizer,\n",
    "        file_path=file_path,\n",
    "        block_size=128)\n",
    "\n",
    "def create_data_collator(tokenizer):\n",
    "    return DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer,\n",
    "        mlm=False)\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "\n",
    "train_dataset = load_dataset(processed_data_path, tokenizer)\n",
    "data_collator = create_data_collator(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aab053e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3075' max='3075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3075/3075 42:34, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.257900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.272800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.023800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.886500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.758200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete and model saved.\n"
     ]
    }
   ],
   "source": [
    "# Fine-Tune the GPT-2 Model\n",
    "model = GPT2LMHeadModel.from_pretrained('distilgpt2')\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    # fp16=True,  # Disabled mixed precision training\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained('./fine_tuned_gpt2')\n",
    "tokenizer.save_pretrained('./fine_tuned_gpt2')\n",
    "\n",
    "print(\"Fine-tuning complete and model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fdb9271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Responses Using the Fine-Tuned Model\n",
    "def generate_response(query, model, tokenizer, max_length=50):\n",
    "    inputs = tokenizer.encode(query, return_tensors='pt').to(model.device)  # Move inputs to the same device as the model\n",
    "    outputs = model.generate(inputs, max_length=max_length, num_return_sequences=1, no_repeat_ngram_size=2, pad_token_id=tokenizer.eos_token_id)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10b99f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Customer Service Chatbot. Type 'exit' to end the conversation.\n",
      "You: exit\n",
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Integrate with a Chat Interface (simple text-based interface for demo)\n",
    "def chat():\n",
    "    print(\"Welcome to the Customer Service Chatbot. Type 'exit' to end the conversation.\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "        response = generate_response(user_input, model, tokenizer)\n",
    "        print(f\"Chatbot: {response}\")\n",
    "\n",
    "# Run the chat interface\n",
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac8bb8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "eval_file_path = 'Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv'\n",
    "eval_data = pd.read_csv(eval_file_path)\n",
    "\n",
    "# Clean Text Data\n",
    "eval_data['instruction'] = eval_data['instruction'].apply(clean_text)\n",
    "eval_data['response'] = eval_data['response'].apply(clean_text)\n",
    "\n",
    "# Handle missing values\n",
    "eval_data.dropna(subset=['instruction', 'response'], inplace=True)\n",
    "\n",
    "# Concatenate 'instruction' and 'response' for fine-tuning as input-output pairs\n",
    "eval_data['input_output'] = eval_data['instruction'] + ' ' + eval_data['response']\n",
    "\n",
    "# Use a smaller subset of the dataset for quicker evaluation\n",
    "eval_data_subset = eval_data.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# Save the processed data to a text file\n",
    "eval_processed_data_path = 'eval_processed_data.txt'\n",
    "with open(eval_processed_data_path, 'w') as f:\n",
    "    for line in eval_data_subset['input_output']:\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0df4a64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mirayon/Documents/Softwares/anaconda3/lib/python3.11/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='309' max='309' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [309/309 00:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 4.970292091369629, 'eval_runtime': 44.941, 'eval_samples_per_second': 54.939, 'eval_steps_per_second': 6.876}\n",
      "Evaluation Perplexity: 144.0689697265625\n"
     ]
    }
   ],
   "source": [
    "# Load the fine-tuned model and tokenizer\n",
    "model_path = './fine_tuned_gpt2'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Load Dataset and Data Collator\n",
    "eval_dataset = load_dataset(eval_processed_data_path, tokenizer)\n",
    "eval_data_collator = create_data_collator(tokenizer)\n",
    "\n",
    "# Create the Trainer for evaluation\n",
    "eval_trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=eval_data_collator,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = eval_trainer.evaluate()\n",
    "\n",
    "# Calculate perplexity\n",
    "eval_perplexity = torch.exp(torch.tensor(eval_results['eval_loss']))\n",
    "\n",
    "print(\"Evaluation Results:\", eval_results)\n",
    "print(\"Evaluation Perplexity:\", eval_perplexity.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4a0ca33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 4.970292091369629,\n",
       " 'eval_runtime': 44.941,\n",
       " 'eval_samples_per_second': 54.939,\n",
       " 'eval_steps_per_second': 6.876}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10ed0a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144.0689697265625"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_perplexity.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bb5380",
   "metadata": {},
   "source": [
    "## A different approach with Tf-idf Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fd3e366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n",
      "You: I need to cancel purchase\n",
      "Chatbot: I understood that you need assistance with canceling your purchase with the order number {{Order Number}}. We apologize for any inconvenience this may have caused. To initiate the cancellation process, please follow these steps:\n",
      "\n",
      "1. Sign in to your account: Visit our {{Online Company Portal Info}} and login using your credentials.\n",
      "2. Access your order history: Once logged in, navigate to the \"{{Online Order Interaction}}\" or \"{{Online Order Interaction}}\" section.\n",
      "3. Locate the purchase: Look for the order with the specific order number {{Order Number}}.\n",
      "4. Cancel the purchase: Click on the \"{{Online Order Interaction}}\" option associated with the purchase.\n",
      "5. Confirm the cancellation: Follow any further prompts or questions from the system to finalize the cancellation.\n",
      "\n",
      "If you encounter any difficulties or have further questions, our dedicated team is available to assist you. You can reach us during {{Customer Support Hours}} at {{Customer Support Phone Number}} or through the Live Chat feature on our website {{Website URL}}. We appreciate your understanding and value your satisfaction.\n",
      "You: i want assistance canceling order\n",
      "Chatbot: I've decoded that you're seeking assistance with canceling your order with the order number {{Order Number}}. Our team is here to help make this process as smooth as possible. Here's what you need to do:\n",
      "\n",
      "1. Log in to your {{Online Company Portal Info}}: Go to our website and access your account by entering your login credentials.\n",
      "2. Locate Your Orders: Once logged in, find the section labeled '{{Online Order Interaction}}' or '{{Online Order Interaction}}'. This is where you will find a list of all your past purchases.\n",
      "3. Find the Relevant Purchase: Look for the order number {{Order Number}} among the listed orders and click on it for more details.\n",
      "4. Initiate the Cancellation: Within the order details, you will find an option to '{{Online Order Interaction}}'. Please select this to begin the cancellation process.\n",
      "5. Follow any Additional Steps: Depending on the system requirements, you may be asked to provide a reason for canceling or to confirm your decision. Please follow the instructions provided.\n",
      "\n",
      "If you encounter any difficulties or have further questions, our dedicated support team is available to assist you. Feel free to reach out to them during {{Customer Support Hours}} at {{Customer Support Phone Number}} or through the Live Chat feature on our website at {{Website URL}}. Your satisfaction is our top priority, and we'll do our best to assist you with canceling order {{Order Number}}.\n",
      "You: have a problem with canceling order\n",
      "Chatbot: I'm cognizant of the fact that you're facing difficulties canceling your order with the order number {{Order Number}}. I apologize for any inconvenience this may be causing you. Rest assured, I'm here to assist you. To resolve this issue, please follow these steps:\n",
      "\n",
      "1. Sign in to your {{Online Company Portal Info}} using your registered credentials.\n",
      "2. Locate the '{{Online Order Interaction}}' or '{{Online Order Interaction}}' section in your account.\n",
      "3. Find the specific order with the order number {{Order Number}} and click on it to access the details.\n",
      "4. Look for the option that says '{{Online Order Interaction}}' and select it to initiate the cancellation process.\n",
      "5. If prompted, provide any necessary information or feedback to complete the cancellation.\n",
      "\n",
      "If you encounter any further issues or have additional questions, our dedicated customer support team is available during {{Customer Support Hours}}. You can reach us at {{Customer Support Phone Number}} or through the Live Chat feature on our {{Website URL}}. We value your satisfaction and will do everything we can to assist you with canceling your order successfully.\n",
      "You: exit\n",
      "Chatbot: Goodbye! Have a great day!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv'\n",
    "dataset = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocess the instructions by fitting a TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer().fit(dataset['instruction'])\n",
    "\n",
    "# Transform the instructions into TF-IDF vectors\n",
    "instruction_vectors = vectorizer.transform(dataset['instruction'])\n",
    "\n",
    "# Function to find the best matching response for a given user query\n",
    "def generate_response(user_query):\n",
    "    # Transform the user query into a TF-IDF vector\n",
    "    query_vector = vectorizer.transform([user_query])\n",
    "    \n",
    "    # Compute cosine similarity between the user query vector and all instruction vectors\n",
    "    similarities = cosine_similarity(query_vector, instruction_vectors).flatten()\n",
    "    \n",
    "    # Find the index of the most similar instruction\n",
    "    best_match_index = similarities.argmax()\n",
    "    \n",
    "    # Return the corresponding response\n",
    "    return dataset.iloc[best_match_index]['response']\n",
    "\n",
    "# Main loop for the chatbot\n",
    "def chatbot_main():\n",
    "    print(\"Hello! How can I assist you today?\")\n",
    "    while True:\n",
    "        user_query = input(\"You: \")\n",
    "        if user_query.lower() in ['exit', 'quit', 'bye']:\n",
    "            print(\"Chatbot: Goodbye! Have a great day!\")\n",
    "            break\n",
    "        response = generate_response(user_query)\n",
    "        print(f\"Chatbot: {response}\")\n",
    "\n",
    "# Start the chatbot\n",
    "chatbot_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34a09f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n",
      "You: i need to cancel my order\n",
      "Chatbot: I've taken note that you would like to cancel your order with the number {{Order Number}}. I apologize for any inconvenience this may have caused.\n",
      "\n",
      "To proceed with the cancellation, please follow these steps:\n",
      "\n",
      "1. Log into your {{Online Company Portal Info}} using your credentials.\n",
      "2. Navigate to the '{{Online Order Interaction}}' or '{{Online Order Interaction}}' section.\n",
      "3. Locate the order with the number {{Order Number}} and click on it for more details.\n",
      "4. Look for the option labeled '{{Online Order Interaction}}' and select it.\n",
      "5. Confirm the cancellation if prompted by the system.\n",
      "\n",
      "If you encounter any issues or have further questions, our dedicated team is ready to assist you. Please reach out during {{Customer Support Hours}} at {{Customer Support Phone Number}} or through the Live Chat feature on our {{Website URL}}.\n",
      "\n",
      "Your satisfaction is important to us, and we appreciate your understanding.\n",
      "You: I need a help with sign in\n",
      "Chatbot: We've received your message to us regarding the problems you're facing during the sign-up process. We understand the frustration it may cause, and we're here to assist you in resolving those issues. To help us better understand and address your concerns, could you please provide more details about the specific problems you encountered? With this information, we can work towards finding the best possible solution for you and improving our sign-up process for all our users. Your feedback is highly valued, and we appreciate your patience as we work together to resolve this matter.\n",
      "You: I forgot my password.\n",
      "Chatbot: Oh, I completely understand how frustrating it can be to forget your account password. Don't worry, I'm here to assist you in the process of resetting it so you can regain access to your account. Here's what you can do:\n",
      "\n",
      "1. First and foremost, visit our login page at \"{{Login Page URL}}\" to initiate the password reset process.\n",
      "2. Look for the option that says \"{{Forgot Password}}\" and click on it.\n",
      "3. You will be prompted to enter the email address associated with your account. Please provide the correct email address to proceed.\n",
      "4. Once you've entered your email address, an email will be sent to you shortly with instructions on how to reset your password. Please check your inbox, as well as your spam or junk folder, just in case.\n",
      "5. Follow the instructions in the email to create a new password. Make sure to choose a strong and unique password to enhance the security of your account.\n",
      "6. After resetting your password, go back to the login page and use your new password to access your account.\n",
      "\n",
      "If you encounter any difficulties during the process or have any additional questions, please feel free to reach out to me. I'm here to make sure your experience is seamless and you regain access to your account as soon as possible. Stay confident, you'll have access to your account in no time!\"\n",
      "You: Thank you!\n",
      "Chatbot: Let's embark on a voyage of discovery to uncover the treasure trove of shipping methods we offer! Here's the key to unlock our diverse array of delivery options:\n",
      "\n",
      "1. Standard Shipping: This method is ideal for those who prefer a cost-effective and time-efficient option. Expect your package to arrive within {{Date Range}} business days.\n",
      "\n",
      "2. Expedited Shipping: Need your items a little quicker? Our expedited shipping method will deliver your package to your doorstep in {{Date Range}} business days, ensuring a swift and efficient delivery experience.\n",
      "\n",
      "3. Overnight Shipping: For the ultimate in speed and convenience, our overnight shipping option guarantees your package will arrive at its destination by the next business day. Perfect for those last-minute surprises or urgent needs.\n",
      "\n",
      "4. In-Store Pickup: If you prefer a more personalized touch or the convenience of grabbing your package yourself, our in-store pickup service is here for you. Simply select the in-store pickup option during checkout and collect your items from one of our {{Store Location}} at your convenience.\n",
      "\n",
      "Remember, the exact delivery times may vary based on your location and other factors. If you have any further questions or need assistance in selecting the best shipping method for your needs, feel free to ask. We're here to ensure a seamless and satisfactory shipping experience for you!\n",
      "You: Exit\n",
      "Chatbot: Goodbye! Have a great day!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv'\n",
    "dataset = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocess the instructions by fitting a TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer().fit(dataset['instruction'])\n",
    "\n",
    "# Transform the instructions into TF-IDF vectors\n",
    "instruction_vectors = vectorizer.transform(dataset['instruction'])\n",
    "\n",
    "# Function to find the best matching response for a given user query\n",
    "def generate_response(user_query):\n",
    "    # Transform the user query into a TF-IDF vector\n",
    "    query_vector = vectorizer.transform([user_query])\n",
    "    \n",
    "    # Compute cosine similarity between the user query vector and all instruction vectors\n",
    "    similarities = cosine_similarity(query_vector, instruction_vectors).flatten()\n",
    "    \n",
    "    # Find the index of the most similar instruction\n",
    "    best_match_index = similarities.argmax()\n",
    "    \n",
    "    # Return the corresponding response\n",
    "    return dataset.iloc[best_match_index]['response']\n",
    "\n",
    "# Main loop for the chatbot\n",
    "def chatbot_main():\n",
    "    print(\"Hello! How can I assist you today?\")\n",
    "    while True:\n",
    "        user_query = input(\"You: \")\n",
    "        if user_query.lower() in ['exit', 'quit', 'bye']:\n",
    "            print(\"Chatbot: Goodbye! Have a great day!\")\n",
    "            break\n",
    "        response = generate_response(user_query)\n",
    "        print(f\"Chatbot: {response}\")\n",
    "\n",
    "# Start the chatbot\n",
    "chatbot_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fc8f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
